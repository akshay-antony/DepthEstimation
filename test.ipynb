{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1f76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from model import Network\n",
    "from mobile_net import Mobile_Net_Unet\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b723418",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/home/akshay/DepthEstimation/checkpoint_28_kitti.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1df569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile Net Loaded\n"
     ]
    }
   ],
   "source": [
    "model = Mobile_Net_Unet()\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "print(\"Mobile Net Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "930a3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        img = torch.from_numpy(image.transpose((2, 0, 1)))\n",
    "\n",
    "    if image.mode == 'I':\n",
    "        img = torch.from_numpy(np.array(image, np.int32, copy=False))\n",
    "    elif image.mode == 'I;16':\n",
    "        img = torch.from_numpy(np.array(image, np.int16, copy=False))\n",
    "    else:\n",
    "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "    # PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "\n",
    "    if image.mode == 'YCbCr':\n",
    "        nchannel = 3\n",
    "    elif image.mode == 'I;16':\n",
    "        nchannel = 1\n",
    "    elif image.mode == 'RGBA':\n",
    "        nchannel = 3\n",
    "    else:\n",
    "        nchannel = len(image.mode)\n",
    "\n",
    "    img = img.view(image.size[1], image.size[0], nchannel)\n",
    "\n",
    "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "\n",
    "    if isinstance(img, torch.ByteTensor):\n",
    "        return img.float().div(255)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2aa1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/akshay/Downloads/KITTI/data/train/X/2011_09_30_drive_0016_sync_0000000010.png\")\n",
    "target = Image.open(\"/home/akshay/Downloads/KITTI/data/train/target/2011_09_30_drive_0016_sync_0000000010.pngjpg\")\n",
    "left = int(image.size[0]/2-224/2)\n",
    "upper = int(image.size[1]/2-192/2)\n",
    "right = left + 224\n",
    "lower = upper + 192\n",
    "image = image.crop((left, upper, right,lower))\n",
    "image.show()\n",
    "target = target.crop((left, upper, right, lower))\n",
    "target.show()\n",
    "\n",
    "image = to_tensor(image).unsqueeze(axis=0)\n",
    "pr = model(image).detach().numpy()\n",
    "pr = np.transpose(pr[0], (1,2,0))\n",
    "pr = 256 / pr\n",
    "pr /= np.max(pr)\n",
    "PIL_image = Image.fromarray(np.uint8(pr*255)).convert('RGB')\n",
    "PIL_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beaca7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyu_image = Image.open(\"/home/akshay/Downloads/training/rgb/100.jpg\")\n",
    "image = nyu_image.resize((224,224))\n",
    "image.show()\n",
    "target.show()\n",
    "img = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "img = img.view(image.size[1], image.size[0], 3)\n",
    "img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "if isinstance(img, torch.ByteTensor):\n",
    "    img = img.float().div(255)\n",
    "img1 = img.unsqueeze(axis=0)\n",
    "pr = model(img1).detach().numpy()\n",
    "pr = np.transpose(pr[0], (1,2,0))\n",
    "pr = 1000 / pr\n",
    "pr /= np.max(pr)\n",
    "PIL_image = Image.fromarray(np.uint8(pr*255)).convert('RGB')\n",
    "org = Image.open(\"/home/akshay/Downloads/training/depth/100.png\")\n",
    "org = org.resize((224,224))\n",
    "org.show()\n",
    "PIL_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4913c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/home/akshay/DepthEstimation/checkpoint_24.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb35d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Loaded\n"
     ]
    }
   ],
   "source": [
    "model_vgg = Network()\n",
    "model_vgg.load_state_dict(checkpoint['state_dict'])\n",
    "model_vgg.eval()\n",
    "print(\"VGG Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4526d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyu_image = Image.open(\"/home/akshay/Downloads/training/rgb/100.jpg\")\n",
    "image = nyu_image.resize((224,224))\n",
    "image.show()\n",
    "img = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "img = img.view(image.size[1], image.size[0], 3)\n",
    "img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "if isinstance(img, torch.ByteTensor):\n",
    "    img = img.float().div(255)\n",
    "img1 = img.unsqueeze(axis=0)\n",
    "pr = model(img1).detach().numpy()\n",
    "pr = np.transpose(pr[0], (1,2,0))\n",
    "pr = 1000 / pr\n",
    "pr /= np.max(pr)\n",
    "PIL_image = Image.fromarray(np.uint8(pr*255)).convert('RGB')\n",
    "org = Image.open(\"/home/akshay/Downloads/training/depth/100.png\")\n",
    "org = org.resize((224,224))\n",
    "org.show()\n",
    "PIL_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8393ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/akshay/DepthEstimation/test_dataset_generated/data/rgb/im5_Color_Color.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29967897",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.resize((224,224))\n",
    "img = torch.ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426fe2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.view(image.size[1], image.size[0], 3)\n",
    "img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "if isinstance(img, torch.ByteTensor):\n",
    "    img = img.float().div(255)\n",
    "img1 = img.unsqueeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7309d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference mbnet 0.021291017532348633\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pr = model(img1).detach().numpy()\n",
    "print(\"inference mbnet\", time.time() - start)\n",
    "pr = np.transpose(pr[0], (1,2,0))\n",
    "pr = 35 / pr\n",
    "pr /= np.max(pr)\n",
    "PIL_image = Image.fromarray(np.uint8(pr*255)).convert('RGB')\n",
    "PIL_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71edf820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference mbnet 0.3208310604095459\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pr = model_vgg(img1).detach().numpy()\n",
    "print(\"inference mbnet\", time.time() - start)\n",
    "pr = np.transpose(pr[0], (1,2,0))\n",
    "pr = 35 / pr\n",
    "pr /= np.max(pr)\n",
    "PIL_image = Image.fromarray(np.uint8(pr*255)).convert('RGB')\n",
    "PIL_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98566f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
